networks:
  hadoop_network:
    driver: bridge

services:
  nifi:
    build:
      context: ./nifi/
    hostname: nifi
    env_file:
      - secrets/nifi.auth.config
    networks:
      - hadoop_network
    volumes:
      - ./nifi/templates:/opt/templates
    
  web-server:
    build:
      context: ./http-server/
    hostname: webserver
    env_file:
      - conf/sources.config
    networks:
      - hadoop_network

  namenode:
    image: apache/hadoop:3.4.1
    hostname: namenode
    command: ["/opt/scripts/namenode-init.sh"]
    env_file:
      - conf/hadoop.cluster.config
    environment:
      - ENSURE_NAMENODE_DIR=/tmp/hadoop-root/dfs/name
    volumes:
      - ./scripts/namenode-init.sh:/opt/scripts/namenode-init.sh
    networks:
      - hadoop_network

  hadoop-init:
    build:
      context: ./hadoop-client/
    depends_on:
      - namenode
    hostname: spark-history    
    tty: true
    env_file:
      - conf/sources.config
      - conf/hadoop.init.config
      - conf/spark.log.config
      - conf/spark.history.config
      - secrets/hadoop.nifi.auth.config
    networks:
      - hadoop_network
    volumes:
      - ./dataset:/opt/dataset
      - ./input/:/opt/input

  datanode:
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - conf/hadoop.cluster.config
    networks:
      - hadoop_network

  spark-master:
    image: apache/spark:3.5.0
    hostname: spark-master
    depends_on:
      - hadoop-init
    command: ["/opt/scripts/entrypoint.sh", "master"]
    env_file:
      - conf/spark.log.config
      - conf/spark.master.config
      - secrets/spark.influxdb.auth.config
    networks:
      - hadoop_network
    volumes:
      - ./scripts/entrypoint.sh:/opt/scripts/entrypoint.sh
      - ./target:/opt/app

  spark-worker:
    image: apache/spark:3.5.0
    command: ["/opt/scripts/entrypoint.sh", "worker", "spark://spark-master:7077"]
    tty: true
    depends_on:
      - spark-master
    env_file:
      - conf/spark.log.config
      - conf/spark.worker.config
      - secrets/spark.influxdb.auth.config
    networks:
      - hadoop_network
    volumes:
      - ./scripts/entrypoint.sh:/opt/scripts/entrypoint.sh
      - ./target:/opt/app

  grafana:
    image: grafana/grafana
    restart: always
    networks:
      - hadoop_network
    volumes:
      - ./grafana-data:/var/lib/grafana

  firefox:
    image: jlesage/firefox
    hostname: firefox
    ports:
      - 5800:5800
    networks:
      - hadoop_network
    volumes:
      - ./nifi/templates:/opt/templates

  influxdb:
    image: influxdb:2
    hostname: influxdb
    networks:
      - hadoop_network
    env_file:
      - conf/influxdb.config
      - secrets/influxdb.auth.config