networks:
  hadoop_network:
    driver: bridge

services:
  nifi:
    image: franc/nifi:2.4.0
    hostname: nifi
    networks:
      - hadoop_network
    environment:
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=almeno12caratteri
      - NIFI_SENSITIVE_PROPS_KEY='almeno12caratteri'
    volumes:
      - ./nifi/templates:/opt/templates
    
  web-server:
    image: franc/httpd
    hostname: webserver
    networks:
      - hadoop_network

  namenode:
    image: apache/hadoop:3.4.1
    hostname: namenode
    ports:
      - 9870:9870
      - 8020:8020
    env_file:
      - conf/hadoop.config
    environment:
      - ENSURE_NAMENODE_DIR=/tmp/hadoop-root/dfs/name
    command: ["hdfs", "namenode"]
    networks:
      - hadoop_network

  hdfs-init:
    image: apache/hadoop:3.4.1
    depends_on:
      - namenode
    command: ["sh", "/opt/scripts/init-hdfs.sh"]
    tty: true
    env_file:
      - conf/hadoop.config
    networks:
      - hadoop_network
    volumes:
      - ./scripts/init-hdfs.sh:/opt/scripts/init-hdfs.sh
      - ./dataset:/opt/dataset
      - ./input/:/opt/input

  datanode_1:
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - conf/hadoop.config
    networks:
      - hadoop_network
  
  datanode_2:
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - conf/hadoop.config
    networks:
      - hadoop_network
  
  spark-master:
    image: apache/spark:3.5.0
    hostname: spark-master
    depends_on:
      - hdfs-init
    depends_on:
      - hdfs-init
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    env_file:
      - conf/spark.master.config
    environment:
      INFLUXDB_USER: admin
      INFLUXDB_PASSWORD: almeno12caratteri
      INFLUXDB_TOKEN: almeno12caratteri
    ports:
      - '8080:8080'
      - '7077:7077'
    networks:
      - hadoop_network
    volumes:
      - ./target:/opt/app

  spark-worker:
    image: apache/spark:3.5.0
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    tty: true
    depends_on:
      - spark-master
    env_file:
      - conf/spark.worker.config
    environment:
      INFLUXDB_USER: admin
      INFLUXDB_PASSWORD: almeno12caratteri
      INFLUXDB_TOKEN: almeno12caratteri
    networks:
      - hadoop_network
    volumes:
      - ./target:/opt/app

  firefox:
    image: jlesage/firefox
    hostname: firefox
    ports:
      - 5800:5800
    networks:
      - hadoop_network
    volumes:
      - ./nifi/templates:/opt/templates

  influxdb:
    image: influxdb:2
    hostname: influxdb
    networks:
      - hadoop_network
    ports:
      - 8086:8086
    env_file:
      - conf/influxdb.config
    secrets:
      - influxdb-admin-username
      - influxdb-admin-password
      - influxdb-admin-token

secrets:
  influxdb-admin-username:
    file: secrets/.env.influxdb-admin-username
  influxdb-admin-password:
    file: secrets/.env.influxdb-admin-password
  influxdb-admin-token:
    file: secrets/.env.influxdb-admin-token
  nifi-admin-username:
    file: secrets/.env.nifi-admin-username
  nifi-admin-password:
    file: secrets/.env.nifi-admin-password
