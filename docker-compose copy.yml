networks:
  hadoop_network:
    driver: bridge

services:
  nifi:
    image: franc/nifi:2.4.0
    hostname: nifi
    networks:
      - hadoop_network
    environment:
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=almeno12caratteri
      - NIFI_SENSITIVE_PROPS_KEY='almeno12caratteri'
    volumes:
      - ./nifi/templates:/opt/templates
    
  web-server:
    image: franc/httpd
    hostname: webserver
    networks:
      - hadoop_network

  namenode:
    image: apache/hadoop:3.4.1
    hostname: namenode
    ports:
      - 9870:9870
      - 8020:8020
    env_file:
      - conf/hadoop.config
    environment:
      - ENSURE_NAMENODE_DIR=/tmp/hadoop-root/dfs/name
    command: ["hdfs", "namenode"]
    networks:
      - hadoop_network

  hdfs-init:
    image: franc/hadoop-client:3.4.1
    depends_on:
      - namenode
    command: ["sh", "/opt/scripts/init-hdfs.sh"]
    tty: true
    env_file:
      - conf/hdfs-init.config
    environment:
      - NIFI_USERNAME=admin
      - NIFI_PASSWORD=almeno12caratteri
    networks:
      - hadoop_network
    volumes:
      - ./scripts/init-hdfs.sh:/opt/scripts/init-hdfs.sh
      - ./scripts/start_processor.py:/opt/scripts/start_processor.py
      - ./dataset:/opt/dataset
      - ./input/:/opt/input

  datanode_1:
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - conf/hadoop.config
    networks:
      - hadoop_network
  
  datanode_2:
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - conf/hadoop.config
    networks:
      - hadoop_network
  
  spark-master:
    image: apache/spark:3.5.0
    hostname: spark-master
    depends_on:
      - hdfs-init
    command: ["/opt/scripts/entrypoint.sh", "master"]
    env_file:
      - conf/spark.master.config
    environment:
      INFLUXDB_USER: admin
      INFLUXDB_PASSWORD: almeno12caratteri
      INFLUXDB_TOKEN: almeno12caratteri
    ports:
      - '8080:8080'
      - '7077:7077'
    networks:
      - hadoop_network
    volumes:
      - ./events:/opt/spark/events
      - ./scripts/entrypoint.sh:/opt/scripts/entrypoint.sh
      - ./target:/opt/app
      - ./dataset/data.csv:/opt/dataset/data.csv
      - ./dataset/data.parquet:/opt/dataset/data.parquet

  spark-worker:
    image: apache/spark:3.5.0
    command: ["/opt/scripts/entrypoint.sh", "worker", "spark://spark-master:7077"]
    tty: true
    depends_on:
      - spark-master
    env_file:
      - conf/spark.worker.config
    environment:
      INFLUXDB_USER: admin
      INFLUXDB_PASSWORD: almeno12caratteri
      INFLUXDB_TOKEN: almeno12caratteri
    networks:
      - hadoop_network
    volumes:
      - ./events:/opt/spark/events
      - ./scripts/entrypoint.sh:/opt/scripts/entrypoint.sh
      - ./target:/opt/app
      - ./dataset/data.csv:/opt/dataset/data.csv
      - ./dataset/data.parquet:/opt/dataset/data.parquet

  spark-history:
    image: apache/spark:3.5.0
    hostname: spark-history
    command: ["/opt/scripts/entrypoint.sh", "history"]
    tty: true
    depends_on:
      - spark-master
      - hdfs-init
    env_file:
      - conf/spark.history.config
    networks:
      - hadoop_network
    volumes:
      - ./scripts/entrypoint.sh:/opt/scripts/entrypoint.sh
      - ./events:/opt/spark/events

  firefox:
    image: jlesage/firefox
    hostname: firefox
    ports:
      - 5800:5800
    networks:
      - hadoop_network
    volumes:
      - ./nifi/templates:/opt/templates

  influxdb:
    image: influxdb:2
    hostname: influxdb
    networks:
      - hadoop_network
    ports:
      - 8086:8086
    env_file:
      - conf/influxdb.config
    environment:
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: almeno12caratteri
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: almeno12caratteri